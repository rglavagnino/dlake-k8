version: "3"
services:

    #Monitoreo, se usa air flow
    airflow-webserver:
        hostname: dacairflow
        container_name: airflow_container
        image: 'puckel/docker-airflow:1.10.9' 
        ports:
            - '8085:8080'
        networks:
            - datadac
        volumes:
            - airflow-data:/home/dlake/airflow/airflow/data
            - airflow-logs:/home/dlake/air/airflow/logs
            - /home/rlavagnino/lake/airflow/dags:/usr/local/airflow/dags
            - /home/rlavagnino/lake/airflow/requirements/requirements.txt:/requirements.txt
        restart: on-failure
        healthcheck:
            test: ["CMD", "curl", "-f", "http://myairflow:8080/admin/"]
            interval: 30s
            timeout: 20s
            retries: 3

    # zookeeper monitoreo
    zookeeper:
        hostname: daczookeeper
        container_name: zookeeper_container
        image: 'bitnami/zookeeper:3.7.0' 
        environment:
            - ALLOW_ANONYMOUS_LOGIN=yes
        networks:
            - datadac
        restart: always

    # Nifi extraccion y transformacion de data
    nifi:
        hostname: dacnifi
        container_name: nifi_container
        image: 'apache/nifi:1.14.0'  
        ports:
            - '8091:8080'
        networks:
            - datadac
        volumes:
            - /home/rlavagnino/lake/nifi/nifi-database_repository:/opt/nifi/nifi-current/database_repository
            - /home/rlavagnino/lake/nifi/nifi-flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
            - /home/rlavagnino/lake/nifi/nifi-content_repository:/opt/nifi/nifi-current/content_repository
            - /home/rlavagnino/lake/nifi/nifi-provenance_repository:/opt/nifi/nifi-current/provenance_repository
           
#####
#Cuando se ejecuta la primera vez, si las carpetas del host no existen, si estas existen no hay que hacerlo
#Ejectuar una vez, con la linea comentada
#crear en algun lugar la carpeta nifiPersistent
#despues copiar los archivos de conf de nifi
#-- sudo docker cp a28f4f7b7b4d:/opt/nifi/nifi-current/conf nifiPersistent/
#Revisar si dentro de la carpeta conf, tengan todos esos archivos
#dtetener el contenedor
#copiar en la carpeta conf del server
#reiniciar el contenedor
# cp 399f9f28j3:/home/rlavagnino/lake/nifi/conf/ .
            - /home/rlavagnino/lake/nifi/conf:/opt/nifi/nifi-current/conf

######
            - /home/rlavagnino/lake/nifi/nifi-state:/opt/nifi/nifi-current/state
            - /home/rlavagnino/lake/nifi/logs:/opt/nifi/nifi-current/logs
            - /home/rlavagnino/lake/nifi/jdbc:/opt/nifi/nifi-current/jdbc
            - /home/rlavagnino/lake/nifi/credentials:/opt/nifi/nifi-current/credentials
        environment:
            - NIFI_WEB_HTTP_PORT=8080
            - NIFI_CLUSTER_IS_NODE=true
            - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
            - NIFI_ZK_CONNECT_STRING=daczookeeper:2181
            - NIFI_ELECTION_MAX_WAIT=30 sec
            - NIFI_SENSITIVE_PROPS_KEY='12345678901234567890A'
        restart: on-failure
        healthcheck:
            test: ["CMD", "curl", "-f", "http://mynifi:8080/nifi/"]
            interval: 30s
            timeout: 20s
            retries: 3

    # Flujos de Nifi
    registry:
        hostname: dacregistry
        container_name: registry_container
        image: 'apache/nifi-registry:1.15.0'  
        restart: on-failure
        ports:
            - "18080:18080"
        environment:
            - LOG_LEVEL=INFO
            - NIFI_REGISTRY_FLOW_PROVIDER=file
        volumes:
            - /home/rlavagnino/lake/nifi_reg/database:/opt/nifi-registry/nifi-registry-current/database
            - /home/rlavagnino/lake/nifi_reg/flow_storage:/opt/nifi-registry/nifi-registry-current/flow_storage
        networks:
            - datadac
        healthcheck:
            test: ["CMD", "curl", "-f", "http://dacregistry:18080/nifi-registry/"]
            interval: 30s
            timeout: 20s
            retries: 3

    # base de datos
    postgres:
        hostname: dacpostgres
        container_name: postgres_container
        image: 'postgres:14-bullseye' 
        environment:
            POSTGRES_USER: 'postgres'
            POSTGRES_PASSWORD: 'lapicero2'
            PGDATA: /data/postgres
        volumes:
            - /home/rlavagnino/lake/data/postgres:/data/postgres
        ports:
            - "5432:5432"
        networks:
            - datadac
        restart: on-failure
        healthcheck:
            test: ["CMD", "pg_isready","-U", "postgres"]
            interval: 30s
            timeout: 20s
            retries: 3

    #base de datos
    pgadmin:
        hostname: dacpgadmin
        container_name: pgadmin_container
        image: 'dpage/pgadmin4:6.1'
        environment:
            PGADMIN_DEFAULT_EMAIL: 'rlavagnino@mp.gob.gt'
            PGADMIN_DEFAULT_PASSWORD: 'admin'
            PGADMIN_CONFIG_SERVER_MODE: 'False'
        volumes:
            - /home/rlavagnino/lake/data/pgadmin:/var/lib/pgadmin
        ports:
            - "5050:80"
        networks:
            - datadac
        restart: on-failure
        healthcheck:
            test: ["CMD", "curl", "-f", "http://mypgadmin:80/misc/ping"]
            interval: 30s
            timeout: 20s
            retries: 3

    mongodb:
        hostname: dacmongo
        container_name: mongo_container
        image: mongo:5.0
        ports:
            - 27017:27017
        volumes:
            - /home/rlavagnino/lake/data/mongo:/data/db
        networks:
            - datadac
        environment:
            - MONGO_INITDB_ROOT_USERNAME=admin
            - MONGO_INITDB_ROOT_PASSWORD=lapicero2
    # lago
    minio:
        hostname: dacminio
        container_name: minio_container
        image: 'bitnami/minio:2022' 
        environment:
            - MINIO_ROOT_USER=admin
            - MINIO_ROOT_PASSWORD=lapicero2
            - MINIO_ACCESS_KEY=admin
            - MINIO_SECRET_KEY=lapicero2
            - MINIO_DISTRIBUTED_MODE_ENABLED=yes
            - MINIO_DISTRIBUTED_NODES=minio,minio2,minio3,minio4
            - MINIO_SKIP_CLIENT=yes
        ports:
            - '9000:9000'
            - '9001:9001'
        volumes:
            - '/home/rlavagnino/lake/data1:/data'
        networks:
            - datadac
        healthcheck:
            test: ["CMD", "curl", "-f", "http://dacminio:9000/minio/health/live"]
            interval: 30s
            timeout: 20s
            retries: 3


    minio2:
        hostname: dacminio2
        container_name: minio_container2
        image: 'bitnami/minio:2022'
        environment:
            - MINIO_ROOT_USER=admin
            - MINIO_ROOT_PASSWORD=lapicero2
            - MINIO_ACCESS_KEY=admin
            - MINIO_SECRET_KEY=lapicero2
            - MINIO_DISTRIBUTED_MODE_ENABLED=yes
            - MINIO_DISTRIBUTED_NODES= minio,minio2,minio3,minio4
            - MINIO_SKIP_CLIENT=yes
        volumes:
            - '/home/rlavagnino/lake/data2:/data'

        networks:
            - datadac

    minio3:
        hostname: dacminio3
        container_name: minio_container3
        image: 'bitnami/minio:2022'
        environment:
            - MINIO_ROOT_USER=admin
            - MINIO_ROOT_PASSWORD=lapicero2
            - MINIO_ACCESS_KEY=admin
            - MINIO_SECRET_KEY=lapicero2
            - MINIO_DISTRIBUTED_MODE_ENABLED=yes
            - MINIO_DISTRIBUTED_NODES=minio,minio2,minio3,minio4
            - MINIO_SKIP_CLIENT=yes
        volumes:
            - '/home/rlavagnino/lake/data3:/data'
        networks:
            - datadac 
    

    minio4:
        hostname: dacminio4
        container_name: minio_container4
        image: 'bitnami/minio:2022'
        environment:
            - MINIO_ROOT_USER=admin
            - MINIO_ROOT_PASSWORD=lapicero2
            - MINIO_ACCESS_KEY=admin
            - MINIO_SECRET_KEY=lapicero2
            - MINIO_DISTRIBUTED_MODE_ENABLED=yes
            - MINIO_DISTRIBUTED_NODES=minio,minio2,minio3,minio4
            - MINIO_SKIP_CLIENT=yes
        volumes:
            - '/home/rlavagnino/lake/data4:/data'
        networks:
            - datadac

#Elastic search
            
    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:7.12.0
        container_name: elasticsearch_container
        restart: always
        hostname: dacelastic
        environment:
            - xpack.security.enabled=false
            - discovery.type=single-node
            - "ES_JAVA_OPTS=-Xms1g -Xmx1g"        
        cap_add: 
            - IPC_LOCK
        networks:
            - datadac
        volumes:
            - /home/rlavagnino/lake/data/elastic:/home/dlake/elasticsearch/data
        ports:
            - "9200:9200"
            
    kibana:
        container_name: kibana_container
        image: docker.elastic.co/kibana/kibana:7.12.0
        restart: always
        networks:
            - datadac
        environment:
            SERVER_NAME: kibana
            ELASTICSEARCH_HOSTS: http://elasticsearch:9200
        ports:
            - "5601:5601"
        depends_on:
            - elasticsearch

volumes:
    airflow-data:
    airflow-logs:
    nifi-database_repository:
    nifi-flowfile_repository:
    nifi-content_repository:
    nifi-provenance_repository:
    nifi-state:
    nifi-conf:
    nifi_registry-database:
    nifi_registry-flow_storage:
    elasticsearch-data-volume:
    postgres:
    pgadmin:

networks:
    datadac:
        driver: bridge
